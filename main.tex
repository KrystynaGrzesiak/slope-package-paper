\documentclass[article]{jss}

\usepackage{orcidlink,thumbpdf,lmodern}
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}

\usepackage{amssymb,amsmath,amsthm,mathtools,bm}
\usepackage{upquote}

\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts

\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{siunitx}

\usepackage[vlined]{algorithm2e}

\usepackage{enumitem}

\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{crossreftools}
\pdfstringdefDisableCommands{%
  \let\Cref\crtCref
  \let\cref\crtcref
}

\usepackage{todonotes}

\input{tex/macros}

% setup url command for hyperref
\newcommand{\myurl}[1]{\href{https://#1}{\nolinkurl{#1}}}

\author{Johan Larsson~\orcidlink{0000-0002-4029-5945}\\University of Copenhagen
   \And Second Author\\Plus Affiliation}
\Plainauthor{}

\title{Efficient Solvers for SLOPE in \proglang{R}, \proglang{Python}, \proglang{Julia}, and \proglang{C++}}
\Plaintitle{Efficient Solvers for SLOPE in R, Python, Julia, and C++}
\Shorttitle{Efficient Solvers for SLOPE}

\Abstract{
  We present a collection of packages in \proglang{R}, \proglang{Python},
  \proglang{Julia}, and \proglang{C++} to efficiently solve the full
  regularization path for Sorted L-One Penalized Estimation (SLOPE) in
  \proglang{R}, \proglang{Python}, \proglang{Julia}, and \proglang{C++}.
  The packages feature a new and improved implementation of the 
  hybrid coordinate descent algorithm for solving SLOPE, which
  features improved and robust convergence properties.
}

\Keywords{SLOPE, OWL, regularization, generalized linear models, \proglang{R}, \proglang{Python}, \proglang{Julia}, \proglang{C++}}
\Plainkeywords{SLOPE, OWL, regularization, generalized linear models, R, Python, C++}

\Address{
  Johan Larsson\\
  Department of Mathematical Sciences\\
  Faculty of Science\\
  University of Copenhagen\\
  Universitetsparken 5\\
  2100 København Ø, Denmark\\
  E-mail: \email{jolars@posteo.com}\\
  URL: \url{https://jolars.co/}
}

\begin{document}

\section{Introduction}

Sorted L-One Penalized Estimation
(SLOPE)~\citep{bogdan2013,zeng2014,bogdan2015} is a type of
regularized regression that consists of the following convex optimization problem:
\begin{equation}
  \label{eq:slope}
  \minimize_{\beta_0 \in \mathbb{R},\beta \in \mathbb{R}^p}
  \Big(
  P(\beta_0,\beta)
  = F(\beta_0, \beta) + \alpha J_{\lambda}(\beta)
  \Big)
\end{equation}
\(P\) is the primal problem, \(F\) is the loss function, \(\alpha\) a parameter
that controls the strength of regularization, and \(\lambda\) a non-increasing sequence of penalty weights. \(J\) is the
\emph{sorted $\ell_1$ norm}, defined as
\begin{equation}
  \label{eq:sl1}
  J_{\lambda}(\beta) = \sum_{j=1}^p \lambda_j |\beta_{(j)}|, \quad
  \text{where}\quad |\beta_{(1)}| \geq |\beta_{(2)}| \geq \ldots \geq
  |\beta_{(p)}|.
\end{equation}

We will assume that \(F\) takes the following form:
\[
  F(\beta_0, \beta) = \frac{1}{n} \sum_{i=1}^n f(y_i, \beta_0 + x_i^\intercal \beta),
\]
where \(f\) is a convex function, \(y_i\) is the response variable, and
\(x_i\) is the \(i\)th row of the design matrix.

We let \((\hat{\beta}_0, \hat{\beta})\) denote a solution to the problem in \Cref{eq:slope}
and take \(X\) to be the \(n \times p\) design matrix and \(Y\) the
\(n \times m\) response matrix,\footnote{For our case, \(m = 1\) unless
  the model is multinomial logistic regression.} using the convention
of denoting a row of a matrix \(X\) as \(x_i\) and a column as \(x_j\).

SLOPE is a generalization of OSCAR (octagonal shrinkage and clustering
algorithm for regression)~\citep{bondell2008}, which is attained by
setting \(\lambda\) to be a linear sequence, which is typically parameterized as
\(\lambda_j = \theta_1 + \theta_2(p - j)\),\footnote{We have used \(\theta_1,\theta_2\) in place of
  \(\lambda_1,\lambda_2\), used in \citet{bondell2008}, to avoid abusing notation.} where \(\theta_1, \theta_2
\geq 0\)~\citep{figueiredo2014}. It is also a special case of
the lasso~\citep{santosa1986,donoho1994,donoho1995,tibshirani1996},
which is obtained by taking a constant \(\lambda\).

% SLOPE is a flexible method, which comes from the fact that the
% \(\lambda\) sequence can be chosen in many different ways (including
% the two mentioned above).

% net~\citep{zou2005}, the SCAD (smoothly clipped absolute deviation)
% penalty~\citep{fan2001}, and the MCP~(minimax concave
% penalty)~\citep{zhang2010} for sparse regression.

A special property of SLOPE is that it can clusters coefficients by
setting them to the same magnitude~\citep{figueiredo2016,bogdan2022}. This is a natural
consequence of the sorted \(\ell_1\) norm and stems from the fact that

SLOPE is a convex but non-smooth optimization problem. And since there are
algorithms for computing the proximal operator of the sorted \(\ell_1\), based
on to the pool-adjacent-violators algorithm~(PAVA)~\citep{barlow1972}, it is
possible to use proximal gradient descent, including accelerated versions such
as FISTA~\citep{beck2009}. It is also possible to use the alternating direction
method of multipliers (ADMM) method~\citep{boyd2010}. \citet{bogdan2015}, for
instance, uses FISTA.

These methods are well-studied and robust, yet have for related problems such
as the lasso and elastic net been shown to be inferior to coordinate descent
methods~\citep{friedman2007,friedman2010}. For SLOPE, however, coordinate
descent cannot be used directly since the sorted \(\ell_1\) norm is not
separable. This problem was, however, solved by \citet{larsson2023}, who invented a
hybrid combination of proximal gradient and coordinate descent. The
algorithm takes full gradient descent steps interspersed with multiple
coordinate descent passes on the current cluster structure. The gradient descent
steps allow the algorithm to eventually discover the true cluster structure,
while the coordinate descent promote fast convergence.

\section{Mathematical Details}

\subsection{Generalized Linear Models}
\label{sec:glm}

In this section we provide a brief overview of generalized linear models (GLMs)
and introduce the notation used in the following sections. We fist of all,
we remind the reader that our loss function is defined as
\[
  F(\beta_0, \beta) = \frac{1}{n} \sum_{i=1}^n f(y_i, \eta_i),
\]
letting \(\eta_i = x_i^\intercal \beta + \beta_0\) be the
linear predictor.

In a generalized linear model, the response variable \(y_i\) is modelled
as a random variable from an exponential family, and is assumed to depend
conditionally on the linear predictor \(\eta_i\) through
\[
  \E(y_i \mid \eta_i) = \ilink(\eta_i),
\]
whee \(\ilink\) is the inverse link function.

To estimate the parameters of the model, \(\beta_0, \beta\), we form a loss
function from the negative log-likelihood of the target distribution, modeling
its mean parameter through the inverse link funktion applied to the linear
predictor. A special attribute of resulting loss function is that its partial
derivative with respect to \(\eta\) is the
\emph{generalized residual}
\[
  \frac{\partial}{\partial \eta_i} f(y_i, \eta_i) = \ilink(\eta_i) - y_i = r_i.
\]
As a consequence, the gradient of the loss function with respect to \(\beta_0\)
and \(\beta\) can be expressed as
\[
  \frac{\partial}{\partial \beta_j} F(\beta_0,\beta)
  = \frac{1}{n} \sum_{i=1}^n x_{ij} \frac{\partial}{\partial \eta_i} f(y_i, \eta_i)
  = \frac{1}{n} \sum_{i=1}^n x_{ij} r_i
\]

\begin{table}[htpb]
  \centering
  \caption{Loss functions, link functions, and inverse link functions for
    generalized linear models in the SLOPE package. Note that in the case of
    multinomial logistic regression, the input vector-valued, and we allow
    \(\log\) and \(\exp\) to be overloaded to apply element-wise in these cases.
  }
  \label{tab:glm}
  \begin{tabular}{lccc}
    \toprule
    Model       & \(f(y, \eta)\)                                                                          & \(\link(\mu)\)                            & \(\ilink(\eta)\)                               \\
    \midrule
    Gaussian    & \(\frac{1}{2}(y - \eta)^2\)                                                             & \(\mu\)                                   & \(\eta\)                                       \\
    \addlinespace
    Binomial    & \(\log(1 + e^\eta) - \eta y\)                                                           & \(\log \left(\frac{\mu}{1 - \mu}\right)\) & \(\frac{e^\eta}{1 + e^\eta}\)                  \\
    \addlinespace
    Poisson     & \(e^\eta - \eta y\)                                                                     & \(\log(\mu)\)                             & \(e^\eta\)                                     \\
    \addlinespace
    Multinomial & \(\sum_{k=1}^m\left( \frac{e^{\eta_k}}{\sum_{j=1}^m e^{\eta_j}} - y_k \eta_k  \right)\) & \(\log\left(\frac{\mu}{1 - \mu}\right) \) & \(\frac{\exp(\eta)}{\sum_{j=1}^m e^{\eta_j}}\) \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Coordinate Descent for SLOPE}

The primary algorithm of the \pkg{SLOPE} packages is the hybrid
coordinate descent algorithm by \citet{larsson2023}. Since it is described in
detail there, we will only summarize its key points here.

The basic idea of the algorithm is to perform the coordinate descent updates on
the cluster coefficients, rather than directly on the clusters. In effect, we fix the
current cluster and update all coefficients belong to it in a single step.
On its own, this algorithm is not guaranteed to converge since it can only
reorder or merge clusters. In order to guarantee converge, the algorithm must
therefore be combined with proximal gradient descent steps. These steps
are able to split the clusters, which eventually means that the full
algorithm converges to the correct clusters and global minimum.

\begin{algorithm}
  \caption{caption}
  \label{alg:label}
  \KwData{data}
  \KwResult{resul}

  \caption{caption}
\end{algorithm}

The hybrid nature of the algorithm comes with boons of its own.
Indeed, proximal gradient descent algorithms are known to converge under
more general assumptions than coordinate descent algorithms. In effect,
this means that the PGD steps act as a safeguard and fallback
when coordinate descent struggles to converge.

One might imagine that this approach of hybrid algorithms could be
extended to standard Newton methods as well and, moreover, include more
refined heuristics in order to adapt naturally to problem structure.
This, however, is beyond the scope of our current work.

\subsection{Intercept Updates}

If we are in a PGD step, then the intercept is updated as part of the
full gradient step.

If we are in a coordinate descent step, then we can compute the intercept
update at the end of a full pass over the clusters.

\subsection{Convergence Criteria}

Our packages use a duality-based stopping criterion, providing an upper
bound on suboptimality at convergence. To achieve this, we rely
on dual variable centering and scaling in order to obtain a feasible dual
point.

In detail, we transform the primal problem, \(P\), defined in \Cref{eq:slope}, into a
constrained problem:
\begin{equation}
  \label{eq:slope-constrained}
  \begin{aligned}
     & \minimize_{\beta_0 \in \mathbb{R},\beta \in \mathbb{R}^p} &  & \frac{1}{n} \sum_{i=1}^n f(y_i, \eta_i) + \alpha J_{\lambda}(\beta)       \\
    % & \text{subject to}                                              &  & r_i = \link(\bm{x}_i^\intercal \bm{\beta}) - y_i, \quad i = 1, \ldots, n                                            \\
     & \text{subject to}                                         &  & r_i = \ilink(\beta_0 + x_i^\intercal \beta) - y_i, \quad i = 1, \ldots, n \\
  \end{aligned}
\end{equation}

Since \(\beta_0 + x_i^\intercal \beta = g(r_i + y_i)\), we can write the Lagrangian as
\[
  L(\beta_0,\beta,r,\delta) = \frac{1}{n} \sum_{i=1}^n f\big(y_i, g(r_i + y_i)\big) + \alpha J_{\lambda}(\beta) + \sum_{i=1}^n \delta_i \left(g(r_i + y_i) - x_i^\intercal \beta - \beta_0 \right).
\]
This allows us to write the dual problem as
\[
  \begin{aligned}
    D(\delta) & = \inf_r\left( \frac{1}{n} f\left(y_i, g(r_i+y_i)\right) - \delta_i g(r_i+ y_i)\right)         \\
    % & \phantom{={}} + \inf_\beta \left(J_\lambda(\beta) - \delta^\intercal X\beta\right)   \\
    % & \phantom{={}} + \inf_{\beta_0} \left( -\delta^\intercal \bm{1} \beta_0\right)        \\
              & \phantom{={}} - \sup_\beta \big((X^\intercal \delta)^\intercal \beta -  J_\lambda(\beta) \big) \\
              & \phantom{={}} - \sup_{\beta_0} \left( \delta^\intercal \bm{1} \beta_0\right)                   \\
  \end{aligned}
\]
Here, we begin by noting that \(\sup_\beta \big((X^\intercal
\delta)^\intercal \beta -  J_\lambda(\beta) \big)\) is the Fenchel conjugate of
the sorted \(\ell_1\) norm, which is the indicator function of the sorted
\(\ell_1\) dual norm unit ball. Its value is
\[
  \sup_\beta \big(z^\intercal \beta -  J_\lambda(\beta) \big) =
  \begin{cases}
    0      & \text{if } J^*_\lambda(z) \leq 1, \\
    \infty & \text{otherwise},
  \end{cases}
\]
where \(J^*_\lambda(z)\) is the sorted \(\ell_1\) dual norm, defined as~\citep{negrinho2014}
\begin{equation}
  J^*_\lambda(z) = \max_{j=1,2,\dots,p}\left\{ \frac{\sum_{k=1}^j|z_{(k)}|}{\sum_{k=1}^j\lambda_k}\right\}
\end{equation}

Next, observe that \(\sup_{\beta_0} (\delta^\intercal \bm{1} \beta_0) = \infty\) unless
\(\delta^\intercal \bm{1} = 0\).

Taken together, this means that we have the following dual function:
\begin{equation}
  D(\delta) = \begin{cases}
    \frac{1}{n} \sum_{i=1}^n f\left(y_i, g(r_i+y_i)\right) - \delta_i g(r_i+ y_i) & \text{if } J^*_\lambda(X^\intercal \delta) \leq 1 \text{ and } \delta^\intercal \bm{1} = 0 \\
    -\infty,                                                                      & \text{otherwise}.
  \end{cases}
\end{equation}

To obtain a feasible dual point for this problem, we can use the
following fact about the stationarity condition of the primal problem,
namely that
\[
  \sum_{j=1}^k | g_{(j)} | \leq \sum_{j=1}^k \lambda_j |\beta_{(j)}| \quad \forall\; k = 1,2,\dots,p.
\]
where  \(g_j = x_j^\intercal r\) is the \(j\)th component of the gradient of loss function
with respect to \(\beta_j\)
and \(r\) the generalized residual, for which \(r_i = \ilink(x_i^\intercal \beta + \beta_0) - y_i\).

Therefore, a natural candidate dual point is the generalized residual. To be a
feasible point, however, we first center the point by its mean and scale it:
\[
  \delta_j = \frac{r_i - \bar{r}}{\max\left\{1, J_\lambda^*\left(X^\intercal(r - \bar{r})\right) \right\}}
\]
which guarantees feasibility. We then obtain the following duality gap:
\[
  P(\beta_0, \beta) - D(\delta)
\]
As a stopping criterion for the algorithm, we use the relative duality gap
\[
  \frac{P(\beta_0, \beta) - D(\delta)}{\max\big(P(\beta_0, \beta), 10^{-\kappa}\big)}
\]
with \(\kappa\) set in a machine-dependent way.

The duality gap provides an upper bound on suboptimality for the problem, independent
of solver and conditioning of the problem, which is not the case of
convergence criteria based on changes in objective, gradients, or coefficients.

The availability of the duality gap also allows us to employ
duality-gap based safe screening rules~\citep{fercoq2015} and
working set strategies derived from these~\citep{massias2018}, which
could furthermore be used to enhance our strategy with look-ahead
screening rules~\citep{larsson2021a}. However,
as noted in \citet{larsson2022d}, the marginal improvement
of using duality-based screening strategies is minor.
% TODO: Maybe reconsider this!

\subsection{Relaxed SLOPE}

Unlike the lasso, the relaxed version of SLOPE has not been studied in much detail.
There are at least two papers where it is described, but then typically it is
called \emph{debiased} SLOPE. We prefer to use the term \emph{relaxed} here,
since it corresponds closer to the terminology from the lasso literature and
avoids confusion with the debiased lasso~\citep{geer2014}, which is a different
model.

In our packages, we support the relaxed version of SLOPE, and parameterize
this relaxation with a parameter \(\gamma\).

\subsection{Cross-Validation}

The packages support hyper-parameter tuning via iterated \(k\)-fold
cross-validation, with parameterization over \(\alpha\), \(\lambda\) type (BH,
Gaussian type, etc.), \(\gamma\) (SLOPE relaxation parameter).

\subsection{Path Fitting}

Our packages are designed to fit the full regularization path for SLOPE, which
is the sequence of solutions to the problem in \Cref{eq:slope} as \(\alpha\) is varied
from \(\alpha_\text{max}\), at which point the first cluster enters the model,
to a small value of \(\alpha\) at which the model is almost saturated.
We use the same criteria as \citet{friedman2010} for stopping the path early,
except that we stop if the number of \emph{clusters} excluding the zero-cluster
exceeds \(n + 1\) (by default), since the support of SLOPE is limited at \(n\) clusters,
which can potentially exceed the number of non-zero coefficients.\footnote{In practice
  this is quite rare since clusters do not form easily at low levels of regularization.}

Fitting the full regularization path is a natural element of SLOPE and similar
models since an optimal setting for \(\lambda\) is only available under
strict and non-testable assumptions.

\subsection{Screening Rules and Working Sets}

Sparse models, like lasso, SCAD, MCP, and SLOPE, benefit greatly from
so-called \emph{screening rules}, which are used to reduce the dimension of
\(\beta\) in the optimization problem. The basic intuition for this is that
it is possible to estimate the gradient \(\nabla F(\beta) \) for a given SLOPE problem
and use this to determine, via the subdifferential, which coefficients are
likely to be non-zero. This screening rule can either be heuristic or safe:
in the latter case the rule guarantees that excluded features correspond
to zero coefficients in the final model. Heuristic rules, on the other hand,
do not guarantee this and therefore need to be complemented with a pass
over all coefficients at the end to ensure that the optimality conditions
are satisfied. Since they are less conservative, however, the cost of
doing so is typically outweighed by the savings in computation time.
Heuristic and safe rules can be combined, usually at no extra cost since
they both rely on the same gradient information.

In the SLOPE package, we use the strong screening rule for
SLOPE~\citep{larsson2020a}, which is an extension of the working set strategy
for the strong screening rule for the lasso~\citep{tibshirani2012}.

\subsection{Covariance Updates}

\citet{friedman2010} present an alternative coordinate descent update that is
based on pre-computing the Gram matrix \(X^\intercal X\) and then use this to
speed up the updates. As the authors note, this can lead to dramatic speed-ups
for the ordinary lasso (with least-squares loss), but not for other loss
functions and not in the high-dimensional setting.

For SLOPE, however, these covariance updates are not as useful. The
reason for this is that the Gram matrix we need is the collapsed
version \((XP)^\intercal XP\), where \(P\) is the pattern matrix.
Throughout optimization, \(P\) changes, which means that the
precomputed Gram matrix must be updated as well. Though this
might be efficient in a few select cases where there are few
changes in the clusters, we have chosen to avoid this
functionality.

\section{Implementation Details}

\subsection{Clusters}

There are multiple ways to handle the cluster structure for SLOPE.
In theory, the most efficient solution would be to use a
doubly-linked list, which offers \(O(1)\) deletion and insertion.
This is a natural construct for the cluster structure, since we
traverse the list linearly as part of the thresholding operator.

Nevertheless, this turns out to be a poor choice in practice.
The discussion is beyond the scope of this paper, but the main
reason is that doubly-linked lists suffer from poor cache
locality, which is a major bottleneck in modern processors.

Instead, we use the following structure:

\begin{description}
  \item[\code{c}] The coefficients of the clusters
  \item[\code{c\_idx}] Pointers to the coefficients in the cluster
  \item[\code{c\_ptr}] Values of the cluster pointers
\end{description}

This structure bears semblance to typical implementations of
sparse matrices.

Pattern~\citep{schneider2022}

\subsection{Thresholding Operator}

The SLOPE thresholding operator is the analogue to the
soft-thresholding operator for the lasso. But unlike the
latter, which is trivial to compute, the SLOPE thresholding operator
needs to conduct a search over the clusters in order to find correct
solution. This leads to a worst-case complexity of
\(\mathcal{O}(K)\), which could be prohibitive in practice.
Fortunately, the situation is much less dire in practice, since
the order of the clusters typically stabilizes early. Instead, the
bulk of the computational time is spent on computing the gradient.
For this reason we use a linear search, which, although suboptimal
theoretically, is faster than a binary search in practice.

We have, however, improved the implementation of
operator by \citet{larsson2023} significantly. In their implementation,
partial \(\lambda\) sums were in each iteration of the search, which
for some cases could lead to large overhead when updating
a large cluster. In our implementation, we instead use a lazy
evaluation strategy based on the cumulative sum of the \(\lambda\) array,
which causes no additional overhead.

\subsection{Sparsity}

Our package is based on the Eigen C++ library and works naturally with sparse
design matrices. These can be created directly through the
\pkg{Matrix}~(\proglang{R}), \pkg{scipy}~(\proglang{Python}), and \pkg{SparseArrays}~(\proglang{Julia}) packages in
and can be passed directly to the C++ API with negligible overhead
and without copying. Coefficients are returned in a sparse format, which
allows for efficient storage and retrieval of the coefficients.

\subsection{Parallelization}

The software is parallelized using OpenMP, which is supported
on all major platforms\footnote{Although overhead for creating
  multiple threads is considerably more demanding on Windows}.
Functions make use of heuristics to determine whether to
spawn multiple threads depending on problem size, except for
the embarassingly parallel case of cross-validation, which is always
parallelized.

\subsection{Feature Normalization}

As shown by \citet{larsson2025}, feature normalization (centering and
scaling the design matrix) can have large consequences for the
solutions. In our packages, we provide multiple different options
for centering and scaling, independently of one another.
We also provide the possibility to manually supply centering
and scaling vectors.

We have also implemented just-in-time (JIT) normalization, which
means that the design matrix does not need to be normalized
in advance. Instead, normalization is performed on-the-fly during
optimization, which means that we can allow arbitrary centering
even of sparse design matrices. In addition, we can completely
avoid copying the design matrix.

\subsection{Out-of-Memory Support}

% TODO: Should we implement this? would be nice.

\subsection{Implementation}

In this paper we present a collection of packages for solving SLOPE, currently
with support for fitting SLOPE in \proglang{R}, \proglang{Python}, and
\proglang{Julia}. The backbone of all of these packages is based on a
\proglang{C++} library that implements all of the numerical algorithms for
SLOPE, including preprocessing, cross-validation, and path fitting. The
packages for the high-level languages all serve as thin wrappers to the
\proglang{C++} library, with some additional functionality for handling data
and plotting the results. This means that new features and bug fixes propagate
quickly and easily to all these wrapppers and enable users to promptly take
advantage of the latest developments.

The entire suite of packages is open source and licensed under the GPL-3.0 license,
and is available on GitHub~(\Cref{tab:slope-packages}).

\begin{table}[htpb]
  \centering
  \caption{SLOPE packages}
  \label{tab:slope-packages}
  \begin{tabular}{llll}
    \toprule
    Language          & Package        & Repository                         & Documentation                     \\
    \midrule
    \proglang{R}      & \pkg{SLOPE}    & \myurl{github.com/jolars/SLOPE}    & \myurl{jolars.github.io/libslope} \\
    \proglang{Python} & \pkg{sortedl1} & \myurl{github.com/jolars/sortedl1} & \myurl{jolars.github.io/sortedl1} \\
    \proglang{Julia}  & \pkg{SLOPE.jl} & \myurl{github.com/jolars/SLOPE.jl} & \myurl{jolars.github.io/SLOPE.jl} \\
    \proglang{C++}    & \pkg{slope}    & \myurl{github.com/jolars/libslope} & \myurl{jolars.github.io/libslope} \\
    \bottomrule
  \end{tabular}
\end{table}

This is made possible via several pieces of software that enable us to link the
API from our \proglang{C++} library to the high-level languages. This includes
\pkg{Rcpp}~\citep{eddelbuettel2011} and \pkg{RcppEigen}~\citep{bates2013} for
\proglang{R}, \pkg{pybind11}~\citep{jakob2025}, and \pkg{CxxWrap}~\citep{janssens2020} for
\proglang{Julia}.

\section{Examples}

In this section we will show how to use the packages to fit SLOPE models in
the different languages.

The packages are
available through the respective package managers for each language, and can be
be installed using the following commands:

\begin{description}[labelwidth=8ex]
  \item[\proglang{R}] \code{install.packages("SLOPE")}
  \item[\proglang{Python}] \code{pip install sortedl1}
  \item[\proglang{Julia}] \code{using Pkg; Pkg.add("SLOPE")}
\end{description}

Assuming that we have loaded a data set consisting of a design
matrix \code{x} and response vector \code{y}, we can fit the full regularization
path for the SLOPE model using the
\pkg{SLOPE} package in \proglang{R} using
\begin{Code}
  library(SLOPE)

  fit <- SLOPE(x, y)
\end{Code}

In \proglang{Python}, the equivalent code would be:
\begin{Code}
  from sortedl1 import Slope

  model = Slope()
  model.fit(x, y)
\end{Code}

In Julia, the package can be loaded and run on a simple dataset as follows:
\begin{Code}
  using SLOPE

  fit = slope(x, y)
\end{Code}

Meanwhile, if one wanted to use the C++ library directly, the following code
would suffice:
\begin{Code}
  #include <slope/slope.h>

  slope::Slope model;
  auto path_result = model.path(x, y);
\end{Code}

\section{Benchmarks}

As part of this project, as well as the work by \citet{larsson2023}, we have
developed a benchmark for SLOPE using \pkg{benchopt}~\citep{moreau2022a}: a
command-line interface and Python library for creating and managing
benchmarks of algorithms for optimization. The benchmark for
SLOPE is available at \myurl{github.com/benchopt/benchmark\_slope}, which
features all the SLOPE packages.

For this paper, we have run the benchmarks for some real data sets~\Cref{tab:real-datasets},
as well as simulated data.

\begin{table}[htpb]
  \centering
  \caption{}
  \label{tab:real-datasets}
  \begin{tabular}{ll}
    \toprule
    Column 1 & Column 2 \\
    \midrule
    a        & b        \\
    c        & d        \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{description}
  \item[sortedl1] The python package of our implementation of the hybrid
        proximal gradient/coordinate descent algorithm described in this work and
        \citet{larsson2023}.
  \item[PGD] The proximal gradient descent algorithm, which is a standard
        algorithm for solving convex optimization problems~\citep{wright2009}. We use a
        analytical computation of the Lipschitz constant to pick the step size.
  \item[PGD-Anderson] The PGD algorithm with Anderson acceleration, which is a
        method for accelerating the convergence of fixed-point
        iterations~\citep{anderson1965,zhang2020}.
  \item[PGD-BB] The PGD algorithm with Barizilai--Borwein~\citep{barzilai1988} step sizes.
  \item[PGD-Safe] A PGD-based algorithm using safe screening rules~\citep{elvira2023}.
  \item[FISTA] An accelerated version of PGD~\citep{beck2009}.
  \item[ADMM] The alternating direction method of
        multipliers~\citep{glowinski1975,boyd2010}, which is a popular algorithm
        for solving convex optimization problems with constraints.
  \item[Newt-ALM] A semi-smooth Newton-based method~\citep{luo2019}. We use the
        implementation of this method from \citet{larsson2023}.
  \item[skglm] Another implementation of FISTA, but with working sets, from the
        \pkg{skglm} package~\citep{bertrand2022}.
  \item[SlopePath] An approximate homotopy method by \citet{dupuis2024},
        which is similar to the lars algorithm for the lasso~\citep{efron2004}.
\end{description}

\bibliography{main}

\newpage

\begin{appendix}

\end{appendix}

\end{document}
