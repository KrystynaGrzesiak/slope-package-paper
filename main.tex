\documentclass[article]{jss}

\usepackage{orcidlink,thumbpdf,lmodern}
\usepackage{amssymb,amsmath,amsthm,mathtools,bm}
\usepackage{upquote}

\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts

\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{siunitx}

\usepackage[linesnumbered,vlined,ruled]{algorithm2e}

\usepackage{enumitem}

\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{crossreftools}
\pdfstringdefDisableCommands{%
  \let\Cref\crtCref
  \let\cref\crtcref
}

\usepackage{todonotes}

% Workaround for Gin settings
\makeatletter
\let\natwidth\Gin@nat@width
\makeatother

\input{tex/macros}

% setup url command for hyperref
\newcommand{\myurl}[1]{\href{https://#1}{\nolinkurl{#1}}}

\author{Johan Larsson~\orcidlink{0000-0002-4029-5945}\\University of Copenhagen
   \And Second Author\\Plus Affiliation}
\Plainauthor{}

\title{Efficient Solvers for SLOPE in \proglang{R}, \proglang{Python}, \proglang{Julia}, and \proglang{C++}}
\Plaintitle{Efficient Solvers for SLOPE in R, Python, Julia, and C++}
\Shorttitle{Efficient Solvers for SLOPE}

\Abstract{
  We present a collection of packages in \proglang{R}, \proglang{Python},
  \proglang{Julia}, and \proglang{C++} to efficiently solve the full
  regularization path for Sorted L-One Penalized Estimation (SLOPE) in
  \proglang{R}, \proglang{Python}, \proglang{Julia}, and \proglang{C++}.
  The packages feature a new and improved implementation of the 
  hybrid coordinate descent algorithm for solving SLOPE, which
  features improved and robust convergence properties.
}

\Keywords{SLOPE, OWL, regularization, generalized linear models, \proglang{R}, \proglang{Python}, \proglang{Julia}, \proglang{C++}}
\Plainkeywords{SLOPE, OWL, regularization, generalized linear models, R, Python, C++}

\Address{
  Johan Larsson\\
  Department of Mathematical Sciences\\
  Faculty of Science\\
  University of Copenhagen\\
  Universitetsparken 5\\
  2100 København Ø, Denmark\\
  E-mail: \email{jolars@posteo.com}\\
  URL: \url{https://jolars.co/}
}

\begin{document}

\section{Introduction}

Sorted L-One Penalized Estimation
(SLOPE)~\citep{bogdan2013,zeng2014,bogdan2015} is a type of
regularized regression that consists of the following convex optimization problem:
\begin{equation}
  \label{eq:slope}
  \minimize_{\beta_0 \in \mathbb{R},\beta \in \mathbb{R}^p}
  \Big(
  P(\beta_0,\beta)
  = F(\beta_0, \beta) + \alpha J_{\lambda}(\beta)
  \Big)
\end{equation}
where \(P\) is the primal problem, \(F\) is the loss function, \(\alpha\) a parameter
that controls the strength of regularization, and \(\lambda\) a non-increasing sequence of penalty weights. \(J\) is the
\emph{sorted $\ell_1$ norm}, defined as
\begin{equation}
  \label{eq:sl1}
  J_{\lambda}(\beta) = \sum_{j=1}^p \lambda_j |\beta_{(j)}|, \quad
  \text{where}\quad |\beta_{(1)}| \geq |\beta_{(2)}| \geq \ldots \geq
  |\beta_{(p)}|.
\end{equation}

We will assume that \(F\) takes the following form:
\[
  F(\beta_0, \beta) = \frac{1}{n} \sum_{i=1}^n f(y_i, \beta_0 + x_i^\intercal \beta),
\]
where \(f\) is a convex function, \(y_i\) is the response variable, and
\(x_i\) is the \(i\)th row of the design matrix.

We let \((\hat{\beta}_0, \hat{\beta})\) denote a solution to the problem in \Cref{eq:slope}
and take \(X\) to be the \(n \times p\) design matrix and \(Y\) the
\(n \times m\) response matrix,\footnote{For our case, \(m = 1\) unless
  the model is multinomial logistic regression.} using the convention
of denoting a row of a matrix \(X\) as \(x_i\) and a column as \(x_j\).

SLOPE is a generalization of OSCAR (octagonal shrinkage and clustering
algorithm for regression)~\citep{bondell2008}, which is attained by
setting \(\lambda\) to be a linear sequence, which is typically parameterized as
\(\lambda_j = \theta_1 + \theta_2(p - j)\),\footnote{We have used \(\theta_1,\theta_2\) in place of
  \(\lambda_1,\lambda_2\), used in \citet{bondell2008}, to avoid abusing notation.} where \(\theta_1, \theta_2
\geq 0\)~\citep{figueiredo2014}. It is also a special case of
the lasso~\citep{santosa1986,donoho1994,donoho1995,tibshirani1996},
which is obtained by taking a constant \(\lambda\).

% SLOPE is a flexible method, which comes from the fact that the
% \(\lambda\) sequence can be chosen in many different ways (including
% the two mentioned above).

% net~\citep{zou2005}, the SCAD (smoothly clipped absolute deviation)
% penalty~\citep{fan2001}, and the MCP~(minimax concave
% penalty)~\citep{zhang2010} for sparse regression.

A special property of SLOPE is that it can clusters coefficients by
setting them to the same magnitude~\citep{figueiredo2016,bogdan2022}. This is a natural
consequence of the sorted \(\ell_1\) norm, stemming from the fact that
the contribution to the norm of a given coefficient increases disproportionally if it
changes order.

SLOPE is a convex but non-smooth optimization problem. But since the
pool-adjacent-violators algorithm~(PAVA)~\citep{barlow1972} can be used to
efficiently\footnote{At an average \(p \log p\) rate, due to the limiting
  sorting operation.} compute the proximal operator of the sorted \(\ell_1\)
norm, it is possible to use a wide range of proximal algorithms, such
as proximal gradient descent, to solve SLOPE. This also includes accelerated
methods such as FISTA~\citep{beck2009}, which is used in the original
implementation of SLOPE by \citet{bogdan2015}. Other possibilities include
proximal Newton~\citep{lee2014} and the alternating direction method of
multipliers (ADMM) method~\citep{boyd2010}.

For related problems such as the lasso and elastic net, however, these
aforementioned methods have typically been shown to be inferior to coordinate
descent methods~\citep{friedman2007,friedman2010}, which optimize one
coefficient at a time. Unfortunately, coordinate descent requires that the
objective is separable in \(\beta_0, \beta\), which is not the case in SLOPE
due to the permutations involved in the sorted \(\ell_1\) norm, which means
that coordinate descent cannot be used directly. This problem was, however,
overcome by \citet{larsson2023}, who invented a hybrid combination of proximal
gradient and coordinate descent. The algorithm alternates between full gradient
descent steps and coordinate descent on current cluster structure to achieve
robust and fast convergence. So far, however, this algorithm has only
been available in the form of a experimental Python module, packaged
in the supplemental code of \citet{larsson2023}.

In this paper we make this algorithm available to a wide audience, by
presenting a collection of packages in \proglang{R}, \proglang{Python},
\proglang{Julia}, and \proglang{C++}, which both improves upon the original
implementation in terms of performance, robustness, and memory efficiency
as well as greatly expands its feature set.

\subsection{Outline of the paper}

In \Cref{sec:math-details}, we introduce the statistical problem that our
packages solve, namely generalized linear models (GLMs) regularized with the sorted
\(\ell_1\) norm (SLOPE)\footnote{SLOPE is sometimes used only as the procedure
  that uses quadratic loss, but here we adopt a more general terminology and
  let SLOPE be defined for any loss function.}, and provide a brief overview of
the mathematical properties of GLMs and the particular properties of SLOPE.
We discuss the optimization problem and describe the hybrid
coordinate descent algorithm we use for solving SLOPE, focusing on the
improvements we have made to the original algorithm by \citet{larsson2023}.
In \Cref{sec:implementation-details}, we provide a detailed overview of the
software implementations, highlighting technical aspects such as
memory management, parallelization, and convergence criteria.
In \Cref{sec:examples}, we showcase how our packages work in practice,
providing examples of fitting models, plotting, and cross-validation.
Finally, in \Cref{sec:discussion}, we summarize the contributions of this paper
and discuss future work.

\section{Mathematical details}\label{sec:math-details}

In this section, we provide a brief overview of the mathematical
details of the SLOPE optimization problem, including the objective and
the hybrid coordinate descent algorithm used to solve it. We also discuss the
convergence criteria used to determine when the algorithm has converged, and
the path fitting procedure used to compute the full regularization path for SLOPE.

\subsection{Generalized linear models}
\label{sec:glm}

Our packages are designed to solve SLOPE for generalized linear models (GLMs),
in which the loss function is defined as
\[
  F(\beta_0, \beta) = \frac{1}{n} \sum_{i=1}^n f(y_i, \eta_i),
\]
letting \(\eta_i = x_i^\intercal \beta + \beta_0\) be the
linear predictor.

In a generalized linear model, the response variable \(y_i\) is modelled
as a random variable from an exponential family, and is assumed to depend
conditionally on the linear predictor \(\eta_i\) through
\[
  \E(y_i \mid \eta_i) = \ilink(\eta_i),
\]
where \(\ilink\) is the inverse link function.

To estimate the parameters of the model, \(\beta_0, \beta\), we form a loss
function from the negative log-likelihood of the target distribution, modeling
its mean parameter through the inverse link funktion applied to the linear
predictor. A special attribute of resulting loss function is that its partial
derivative with respect to \(\eta\) is the
\emph{generalized residual}
\[
  \frac{\partial}{\partial \eta_i} f(y_i, \eta_i) = \ilink(\eta_i) - y_i = r_i.
\]
As a consequence, the gradient of the loss function with respect to \(\beta_0\)
and \(\beta\) can be expressed as
\[
  \frac{\partial}{\partial \beta_j} F(\beta_0,\beta)
  = \frac{1}{n} \sum_{i=1}^n x_{ij} \frac{\partial}{\partial \eta_i} f(y_i, \eta_i)
  = \frac{1}{n} \sum_{i=1}^n x_{ij} r_i
\]

We summarize the loss functions, link functions, and inverse link functions
for the GLMs supported by the SLOPE packages in \Cref{tab:glm}.

\begin{table}[t!]
  \centering
  \label{tab:glm}
  \begin{tabular}{lccc}
    \toprule
    Model       & \(f(y, \eta)\)                                                                                       & \(\link(\mu)\)                            & \(\ilink(\eta)\)                                       \\
    \midrule
    Gaussian    & \(\frac{1}{2}(y - \eta)^2\)                                                                          & \(\mu\)                                   & \(\eta\)                                               \\
    \addlinespace
    Binomial    & \(\log(1 + e^\eta) - \eta y\)                                                                        & \(\log \left(\frac{\mu}{1 - \mu}\right)\) & \(\frac{e^\eta}{1 + e^\eta}\)                          \\
    \addlinespace
    Poisson     & \(e^\eta - \eta y\)                                                                                  & \(\log(\mu)\)                             & \(e^\eta\)                                             \\
    \addlinespace
    Multinomial & \(\sum_{k=1}^{m-1}\left( \log \left( 1 +  \sum_{j=1}^{m-1} e^{\eta_j}\right) - y_k \eta_k  \right)\) & \(\log\left(\frac{\mu}{1 - \mu}\right) \) & \(\frac{\exp(\eta)}{1 + \sum_{j=1}^{m-1} e^{\eta_j}}\) \\
    \bottomrule
  \end{tabular}
  \caption{Loss functions, link functions, and inverse link functions for
    generalized linear models in the SLOPE package. Note that in the case of
    multinomial logistic regression, the input is vector-valued, and we allow
    \(\log\) and \(\exp\) to be overloaded to apply element-wise in these cases.
  }
\end{table}

A particular case of interest is the multinomial logistic regression model.
Many implementations of regularized multinomial logistic regression models, such
as those by \citet{friedman2010} and \citet{fercoq2015} use the \emph{redundant}
\(m\)-class formulation. Here, however, we have opted to use the non-redundant
formulation of the loss function, with the last class serving as the reference
category. This choice complicates notation slightly and leads to a more
complex formulation for the dual problem. For SLOPE, however, this is a
more natural choice since it generalizes to the binary case as well (in which
the last class is also implicit). SLOPE needs a \(\lambda\) sequence of length
\(mp\), so the loss function for the multinomial case would not be equivalent
to the binary case if we used the redundant formulation. Furthermore, the
redundant formulation is not estimable in the absence of regularization, which
is not the case for the non-redundant formulation. This fact also means that a
coordinate descent algorithm needs bounds checks to handle the parameter
ambiguity~\citep{friedman2010}. This is not especially difficult to implement
for the lasso, but is more complicated in the case of SLOPE since rows of the
coefficient matrix cannot be arbitrarily shifted because it would alter the
overall cluster structure.

\subsection{Hybrid algorithm}

The primary algorithm of the \pkg{SLOPE} packages is the hybrid coordinate
descent algorithm by \citet{larsson2023}. Since it is described in detail
there, we will only summarize its key points here and highlight
some of the differences between that implementation and the one presented here.
The basic idea of the algorithm is to perform the coordinate descent updates on
the cluster coefficients, rather than directly on the clusters. In effect, we fix the
current cluster and update all coefficients belong to it in a single step.
On its own, this algorithm is not guaranteed to converge since it can only
reorder or merge clusters. In order to circumvent this, the algorithm must
therefore be combined with proximal gradient descent steps. These steps
are able to split the clusters, which eventually means that the full
algorithm converges to the correct clusters and global minimum.

We have outlined the algorithm in \Cref{alg:hybrid}. Unlike the implementation
in \citet{larsson2023}, this algorithm can be used to solve
any generalized linear model---not just the Gaussian case. To do so,
we use a iteratively reweighted least-squares (IRLS) approach, determining
weights \(w\) and a working response \(z\) after each proximal gradient descent step.
We then run the coordinate descent algorithm for a fixed number of iterations.
Convergence is monitored using a duality-based stopping criterion, which
we check after each gradient is computed. In order to avoid complicating
the presentation, we have omitted the details of the screening rules and duality
gap calculations here.

\begin{algorithm}[tp]
  \caption{
    The Hybrid coordinate descent algorithm for generalized linear models, using
    the IRLS where weights \(w\) and a working response \(z\) are computed
    after a proximal gradient descent step. We describe the cyclical version of
    the algorithm here. \(c^{\setminus k}\) is a version of the vector \(c\)
    with the \(k\)th coefficient omitted and \(T\) is the SLOPE thresholding
    operator, which we have illustrated in \Cref{fig:slope-thresholding}.
  }
  \label{alg:hybrid}
  \SetKwInOut{Input}{input}
  \SetKwComment{tcc}{$\triangleright$ }{}
  \SetCommentSty{textit}

  \Input{%
    \(X \in \mathbb{R}^{n\times p}\),
    \(y\in \mathbb{R}^n\),
    \(\lambda \in \{\mathbb{R}^p : \lambda_1 \geq \lambda_2 \geq \cdots > 0\}\),
    \(v \in \mathbb{N}\)
  }

  \Repeat{\(P(\beta_0, \beta) - D(\theta) \leq \varepsilon|P(\beta_0, \beta)|\)}{

    Set \(t\) with backtracking line search\;

    \(\beta \gets \beta - t \nabla F(\beta_0, \beta)\)\; \label{alg:hybrid-istastep}

    \For{\(i \gets 1,\dots,n\)}{

      \(\eta_i \gets x_i^T \beta + \beta_0 \)\;
      \(w_i \gets \frac{\partial}{\partial \eta_i} f(\eta_i, y_i) \)\tcc*{Weights for IRLS}
      \(z_i \gets \eta_i - \frac{r_i(\eta_i, y_i)}{w_i} \)\tcc*{Working response for IRLS}
    }
    Update \(c\), \(\mathcal{C}\)\;
    \For{\texttt{it} \(\gets 1,\dots,\)\texttt{cd\_maxit}}{
      \(k \gets 1\)\;
      \(\beta^\text{old} \gets \beta\)\;

      \While{\(k \leq \lvert \mathcal{C} \rvert\)}{
        \(\tilde x \gets \sum_{j \in \cC_k} x_j \sign \beta_j \)\;
        \(\tilde{r} \gets X \beta + \beta_0 - z\)\tcc*{Residuals}
        \(\gamma \gets \frac{1}{n} \sum_{i=1}^n w_i \tilde{x}_i \tilde{r}_i\)\tcc*{Gradient}
        \(\xi \gets \frac{1}{n} \sum_{i=1}^n w_i \tilde{x}_i^2 \)\tcc*{Hessian}
        \(\tilde {c} \gets T(c_k \xi - \gamma; \xi, c^{\setminus k}, \lambda)\)\;
        \(\beta_{\cC_k} \gets \tilde{c} \sign(\beta_{\cC_k})\)\;
        Update \(c\), \(\mathcal{C}\)\;
        \(k \gets k + 1\)\;
      }

      \If{\(P(\beta) \geq P(\beta^\text{old})\)}{
        \(\beta \gets \beta^\text{old}\)\;
        break\;
      }
    }
  }

\end{algorithm}

\begin{figure}[t]
  \centering
  \includegraphics[width=\natwidth]{images/slope-thresholding.pdf}
  \caption{
  An illustration of the SLOPE thresholding operator, adapted from
  \citet{larsson2023}. We define \(S(x) = \sum_{j \in
    C(x)}\lambda_{(j)^-_{x}}\) and let \(\varepsilon_c > 0\) be defined such that
  \(\varepsilon_c < \big| c_i - c_j\big|\;\forall\, i \neq j\) and
  \(\varepsilon_c < c_m\) if \(c_m \neq 0\).
  }
  \label{fig:slope-thresholding}
\end{figure}

The hybrid nature of the algorithm comes with benefits of its own. One such is
that proximal gradient descent algorithms are known to converge under more
general assumptions than coordinate descent algorithms~\citep{wright2015},
which means that the PGD part of the algorithm can serve as a fallback in case
the coordinate descent part does not converge. In practice, we store the
current solution before updating and revert to it if the coordinate descent
step does not improve the primal objective.

The implementation in \citet{larsson2023} used a type of cyclical coordinate
descent in which the algorithm iterated over the clusters in descending order
by their coefficients' magnitudes. Although simple to implement
and efficient for many problems, we have found this
algorithm to suffer under convergence issues in a few cases.
For the current implementation, we have therefore also
implemented a version using random permutations, which we have found to be more
robust at little extra cost.

\subsection{Convergence criteria}

Our packages use a duality-based stopping criterion, providing an upper bound
on suboptimality at convergence. We transform the primal problem into a
constrained formulation and derive a dual problem that allows us to compute a
duality gap. As a stopping criterion, we use the relative duality gap: \[
  P(\beta_0, \beta) - D(\delta) \leq \varepsilon | P(\beta_0, \beta) |, \] where
\(\varepsilon >0\) is the user-defined tolerance level. This provides a
reliable, solver-independent measure of convergence. The complete derivation of
the dual problem and the calculation of the duality gap is provided in
\Cref{sec:convergence-criteria-details}.

\subsection{Path fitting}

Our packages are optimized for fitting the full regularization path for SLOPE, which
is the sequence of solutions to the problem in \Cref{eq:slope} as \(\alpha\) is varied
from \(\alpha_\text{max}\), at which point the first cluster enters the model,
to a small value of \(\alpha\) at which the model is almost saturated.
We use the same criteria as \citet{friedman2010} for stopping the path early,
except that we stop if the number of \emph{clusters} excluding the zero-cluster
exceeds \(n + 1\) (by default), since the support of SLOPE is limited at \(n\) clusters,
which can potentially exceed the number of non-zero coefficients.\footnote{In practice
  this is quite rare since clusters do not form easily at low levels of regularization.}

Since optimal settings of \(\alpha\) are only available under
strict assumptions that are typically hard to test, it is common to
instead use cross-validation to tune \(\alpha\) over a grid of values.
In practice, this means that we repeatedly have to fit the full SLOPE
path, which makes path-fitting a key part of the implementation.

\subsection{Screening rules}

Sparse models like lasso and SLOPE are well-known to benefit from
\emph{screening rules}, which are used to reduce the dimension of \(\beta\) in
the optimization problem and thereby speed up optimization. The intuition for
this is that it is possible to estimate the gradient \(\nabla F(\beta) \) for a
given SLOPE problem and, via the subdifferential, estimate the support of the
solution: the identity of the nonzero coefficients. Screening rules are
either \emph{heuristic} or \emph{safe}. In the latter case the rule guarantees that
excluded predictors correspond to zero coefficients in the final model. Heuristic
rules, on the other hand, do not guarantee this and therefore need to be
complemented with a pass over all coefficients at the end to ensure that the
optimality conditions are satisfied. Since they are less conservative, however,
the cost of doing so is typically outweighed by the savings in computation
time.

In the SLOPE package, we use the strong screening rule for
SLOPE~\citep{larsson2020a}, which is an extension of the working set strategy
for the strong screening rule for the lasso~\citep{tibshirani2012}.

\section{Implementation details}
\label{sec:implementation-details}

In this section, we provide a detailed overview of the implementation
details of the SLOPE packages, including the data structures used to represent
the clusters, the thresholding operator, and parallelization strategies.

\subsection{Software}
\label{sec:software}

We have implemented a collection of packages for solving SLOPE, currently with
support for \proglang{R}, \proglang{Python}, and \proglang{Julia}. The backbone
of all of these packages is based on a \proglang{C++} library that implements
all of the numerical algorithms for SLOPE, including preprocessing,
cross-validation, and path fitting. The packages for the high-level languages
all serve as thin wrappers to the \proglang{C++} library, with some additional
functionality for handling data and plotting the results. This means that new
features and bug fixes propagate quickly and easily to all these wrapppers and
enable users to promptly take advantage of the latest developments. The entire
suite of packages is open source and licensed under the GPL-3.0 license, and is
available on GitHub~(\Cref{tab:slope-packages}).

\begin{table}[tp]
  \centering
  \begin{tabular}{llll}
    \toprule
    Language          & Package        & Repository                         & Documentation                     \\
    \midrule
    \proglang{R}      & \pkg{SLOPE}    & \myurl{github.com/jolars/SLOPE}    & \myurl{jolars.github.io/SLOPE}    \\
    \proglang{Python} & \pkg{sortedl1} & \myurl{github.com/jolars/sortedl1} & \myurl{jolars.github.io/sortedl1} \\
    \proglang{Julia}  & \pkg{SLOPE.jl} & \myurl{github.com/jolars/SLOPE.jl} & \myurl{jolars.github.io/SLOPE.jl} \\
    \proglang{C++}    & \pkg{slope}    & \myurl{github.com/jolars/libslope} & \myurl{jolars.github.io/libslope} \\
    \bottomrule
  \end{tabular}
  \caption{A summary of the suite of packages that we have developed for solving SLOPE, along
    with links to the source code repositories and documentation.}
  \label{tab:slope-packages}
\end{table}

This is made possible via several pieces of software that enable us to link the
API from our \proglang{C++} library to the high-level languages. This includes
\pkg{Rcpp}~\citep{eddelbuettel2011} and \pkg{RcppEigen}~\citep{bates2013} for
\proglang{R}, \pkg{pybind11}~\citep{jakob2025}, and \pkg{CxxWrap}~\citep{janssens2020} for
\proglang{Julia}.

\subsection{Clusters}
\label{sec:clusters}

Handling the cluster structure of SLOPE is a key part of the algorithm since we
will both be iterating over the clusters as part of the coordinate descent
updates as well as updating the clusters after each update. In our
implementation, we represent the clusters as a collection of three vectors:

\begin{description}
  \item[\code{c}] The coefficients of the clusters
  \item[\code{c\_idx}] Pointers to the coefficients in the cluster
  \item[\code{c\_ptr}] Values of the cluster pointers
\end{description}

In this representation, the indices for the \(k\)th cluster are given by \code{
c_idx[c_ptr[k] : c_ptr[k+1]]} and the coefficient is simply \code{c[k]}.

This structure is the same basic setup as in \citet{larsson2023}. Unlike
their implementation, however, we have made improvements to the
handling of updating the clusters (merging,
reordering, removal), which can now be performed with negligible
overhead and with minimal copying.

\subsection{Thresholding operator}

The SLOPE thresholding operator~(\Cref{fig:slope-thresholding}) is the analogue
to the soft-thresholding operator for the lasso. But unlike the latter, which
is trivial to compute, the SLOPE thresholding operator needs to conduct a
search over the clusters in order to find correct solution. This leads to a
worst-case complexity that depends on the number of clusters, which could be prohibitive in
practice. Fortunately, the situation is much less dire in practice, since the
order of the clusters typically stabilizes early. Instead, the bulk of the
computational time is spent on computing the gradient. For this reason we use a
linear search, which, although suboptimal theoretically, is faster than a
binary search in practice.

We have, however, improved the implementation of operator by
\citet{larsson2023} significantly. In their implementation, partial \(\lambda\)
sums were computed in each iteration of the search, which for some cases could
lead to large overhead when updating a large cluster. In our implementation, we
instead evaluate these sums lazily based on the cumulative sum of the
\(\lambda\) array, which for some cases lead to a significant speedups.

\subsection{Sparsity}

Our package is based on the \pkg{Eigen} \proglang{C++} library and provides
support for both dense and sparse design matrices. The latter can be
constructed through the \pkg{Matrix}~(\proglang{R}),
\pkg{scipy}~(\proglang{Python}), and \pkg{SparseArrays}~(\proglang{Julia})
packages in and are passed to the \proglang{C++} API without copying
and with negligible overhead. Coefficients are returned in a sparse format, which
allows for efficient storage and retrieval of the coefficients.

\subsection{Parallelization}

The software is parallelized using \pkg{OpenMP}, which is supported on all
major platforms\footnote{Since the overhead for spawning multiple threads is,
  however, high on Windows, the benefits of multi-threading are there in
  practice limited to cross-validation.}. Functions make use of heuristics to
determine whether to spawn multiple threads depending on problem size, except
for the case of cross-validation, which is always parallelized.

\subsection{Normalization}

As shown by \citet{larsson2025}, predictor normalization (centering and
scaling the design matrix) may have large consequences for the
solutions. In our packages, we provide multiple different options
for centering and scaling, independently of one another.
We also provide the possibility to manually supply centering
and scaling vectors.

Optionally, normalization is also realized just-in-time (JIT),
which means that the design matrix does not need to be normalized in place.
Normalization is performed as predictors of the design matrix are accessed during
optimization, which allows us to support centering even of sparse design
matrices. This also allows us to completely avoid copying the design matrix.

\subsection{Memory management}
\label{sec:memory-management}

For dense matrices, the packages implement memory-efficient views of
the input matrices in order to avoid copies of the data.\footnote{This is technically achievable for sparse matrices too, but
  would mean heavy overhead since we would need to iterate over all nonzero
  elements for each view. We have thus decided against implementing this.}
This means, for instance, that no copies need to be made when separating
data sets into training and test data.

\subsection{Cross-validation}

Due to the memory-efficient implementation of view~\Cref{sec:memory-management}, we provide
an option to altogether avoid copying the data during cross-validation.
This means that we parallelize the cross-validation procedure over
arbitrarily many folds and repetitions, yet still completely
avoid the need to copy the data.

\subsection{Out-of-memory support}

The SLOPE packages support out-of-memory storage for the design matrix, which
means that users can fit SLOPE models on data sets that are larger than the
available memory. Storage in RAM is therefore limited to the order of \(O(n) +
O(p)\), which means that the packages can be used on huge data sets.

This is supported via the generic \code{Eigen::Map} class, which allows
arbitrary data to be mapped into \pkg{Eigen} data structures. At the
time of writing, this is only supported for \proglang{R},
which is possible via the \pkg{bigmemory} package~\citep{kane2013},
and currently only for dense designs.

\section{Examples}\label{sec:examples}

In this section we will show how to use the packages to fit SLOPE models in
the different languages.

The packages are
available through the respective package managers for each language, and can be
be installed using the following commands:
\begin{description}[labelwidth=8ex]
  \item[\proglang{R}] \code{R> install.packages("SLOPE")}
  \item[\proglang{Python}] \code{$ pip install sortedl1}
  \item[\proglang{Julia}] \code{julia> using Pkg; Pkg.add("SLOPE")}
\end{description}

Installing the \proglang{C++} library is slightly more involved, and requires
\pkg{CMake}~\citep{kitware2025} together with a working \proglang{C++} toolchain, including
the \pkg{Eigen} library~\citep{guennebaud2010a} and \pkg{OpenMP}~\citep{dagum1998}.

Assuming that we have loaded a data set consisting of a design
matrix \code{x} and response vector \code{y}, we can fit the full regularization
path for the SLOPE model using the following commands for the different languages:

\begin{minipage}[t]{0.25\textwidth}%
  \textbf{\proglang{R}}
  \begin{Code}
R> library(SLOPE)
R> fit <- SLOPE(x, y)
  \end{Code}
\end{minipage}
\hfill
\begin{minipage}[t]{0.32\textwidth}

  \textbf{\proglang{Python}}
  \begin{Code}
>>> import sortedl1
>>> model = sortedl1.Slope()
>>> res = model.path(x, y)
  \end{Code}
\end{minipage}
\hfill
\begin{minipage}[t]{0.32\textwidth}
  \textbf{\proglang{Julia}}
  \begin{Code}
julia> using SLOPE
julia> fit = slope(x, y)
  \end{Code}
\end{minipage}

\medskip

You can also use the C++ library directly, in
which case the above would translate into the
following:
\begin{Code}
#include <slope/slope.h>
slope::Slope model;
auto path_result = model.path(x, y);
\end{Code}

In the sequel, we will focus our examples on the \proglang{R} package, but
note that the API is very similar in all of the languages.

\subsection{First steps}

We start with a simple example of fitting a full SLOPE path to the diabetes
data set~\citep{efron2004}, including plotting it.

\begin{Code}
R> library(SLOPE)
R> data("diabetes", package = "lars")
R> x <- scale(diabetes$x)
R> y <- diabetes$y
R> fit_slope <- SLOPE(x, y, q = 0.1)
R> plot(fit_slope)
\end{Code}

The \code{q} parameter is a parameter of the sequence of \(\lambda\) values,
which by default~(\code{lambda = "bh"}) is the Benjamini--Hochberg (BH)
sequence~\citep{bogdan2015}. If the design matrix is orthogonal, then the
\code{q} parameter will decide the expected false discovery rate (FDR) in terms
of the identification of true signals (nonzero coefficients), provided
that this sequence is used.

Other types of sequences are also supported,
including \code{lambda = "lasso"} for the lasso
\code{lambda = "oscar"} for the OSCAR sequence~\citep{bondell2008}, and
\code{lambda = "gaussian"} for the Gaussian-type sequence~\citep{bogdan2015},
which is a modification of the BH sequence that has been empirically shown to
provide similar FDR control in non-orthogonal and low-dimensional settings.

To show how the choice of the \(\lambda\) sequence affects the
results, we will refit the diabetes data using the lasso sequence.

\begin{Code}
R> fit_lasso <- SLOPE(x, y, lambda = "lasso")
R> plot(fit_lasso)
\end{Code}

The resulting paths are plotted in \Cref{fig:diabetes}. Observe that the
paths are overall similar but that the SLOPE path has clustered
some coefficients for parts of the path. Predictors 3 and 9, for instance,
enter the path together and remain clustered at the beginning, then
split apart and again cluster together briefly, before diverging again.
We also see that predictor 6 joins the path briefly together
with predictor 5 on the SLOPE path, but then return to zero until
it later enters again on its own.

\begin{figure}[tp]
  \centering
  {\includegraphics[width=\natwidth]{images/diabetes-slope-lasso.pdf}}
  \caption{%
    SLOPE and lasso paths on the diabetes
    data set. Note that the \(x\) axis is reversed. Numbers indicate
    the indices of the predictors.
  }
  \label{fig:diabetes}
\end{figure}

% TODO: We first need to implement this in the package.

\subsection{Relaxed SLOPE}

Unlike the lasso, the relaxed version of SLOPE has not been studied in much detail.
There are at least two papers where it is described, but then typically it is
called \emph{debiased} SLOPE. We prefer to use the term \emph{relaxed} here,
since it corresponds closer to the terminology from the lasso literature and
avoids confusion with the debiased lasso~\citep{geer2014}, which is a different
model.

In our packages, we support the relaxed version of SLOPE, and parameterize
this relaxation with a parameter \(\gamma\).

The relaxation parameter \(\gamma\) controls the mix between the
original SLOPE solution (\(\gamma = 1\) and the fully relaxed
solution (\(\gamma = 0\)), so that
the end result is given by
\[
  \hat{\beta} = \gamma \hat{\beta}_\text{SLOPE} + (1 - \gamma) \hat{\beta}_\text{relaxed}.
\]

Here, we fit two models, one that is fully relaxed
(\(\gamma = 0\)) and one that is semi-relaxed (\(\gamma = 0.5\)).

\begin{Code}
R> fit_relaxed <- SLOPE(x, y, q = 0.1, gamma = 0)
R> fit_semirelaxed <- SLOPE(x, y, q = 0.1, gamma = 0.5)
\end{Code}

We fit the result in \Cref{fig:relaxed-slope}.

\begin{figure}[tp]
  \centering
  \includegraphics[width=\natwidth]{images/slope-relaxed.pdf}
  \caption{%
    SLOPE with various level of relaxation \(\gamma\), with
    \(\gamma = 0\) (fully relaxed), \(\gamma = 0.5\) (semi-relaxed),
    and \(\gamma = 1\) (standard SLOPE).
  }
  \label{fig:relaxed-slope}
\end{figure}

\subsection{Cross-validation}

Our packages support hyper-parameter tuning via iterated \(k\)-fold
cross-validation, with parameterization over \(\alpha\), \(\lambda\) type (BH,
Gaussian type, etc.), \(\gamma\) (SLOPE relaxation parameter).

Here, we show the CV functionality by cross-validating across
to values of the \(q\) parameter.

\begin{CodeChunk}
  \begin{CodeInput}
R> set.seed(48)
R> fit_cv <- cvSLOPE(x, y, q = c(0.1, 0.2))
R> plot(fit_cv)
\end{CodeInput}
  \begin{CodeOutput}
Call:
cvSLOPE(x = x, y = y, q = c(0.1, 0.2))

Optimum values:
      q gamma     alpha measure     mean       se      lo       hi
129 0.2     0 0.3379402     mse 3013.065 234.6321 2482.29 3543.839
\end{CodeOutput}
\end{CodeChunk}

It is also easy to plot the cross-validation results~\Cref{fig:cv}.

\begin{Code}
R> plot(fit_cv)
\end{Code}

\begin{figure}[tp]
  \centering
  \includegraphics[width=\natwidth]{images/slope-cv.pdf}
  \caption{%
    Mean-squared error (MSE) from cross-validation of
    \(q\) and \(\alpha\) for SLOPE fit to the diabetes data set.
    The dashed line marks the optimal value of \(\alpha\) in the
    panel corresponding to the optimal value of \(q\).
  }
  \label{fig:cv}
\end{figure}

It is also possible to cross-validate over the \(\gamma\) parameter, to
find the optimal level of relaxation for SLOPE.

\section{Benchmarks}

In this section, we present benchmarks of the numerical performance of our
implementation for solving SLOPE. In \Cref{sec:single-solution-benchmark}, we examine the performance of SLOPE
when fitting for a single value of \(\alpha\), while in
\Cref{sec:path-benchmark}, we benchmark the performance of fitting
the full regularization path.

Our benchmarks are organized and run using \pkg{benchopt}~\citep{moreau2022a},
and are based upon a version developed by \citet{larsson2023} that we have
extended to include additional solvers. The benchmark is available as a public
git repository at \myurl{github.com/benchopt/benchmark\_slope} and
features the following solvers:\footnote{The \proglang{R} package \pkg{SLOPE} is also
  included, but we have omitted it from the benchmark here since it is essentially equivalent
  to the \proglang{Python} package \pkg{sortedl1}.}

\begin{description}
  \item[sortedl1] The python package of our implementation of the hybrid
        proximal gradient/coordinate descent algorithm described in this work and
        \citet{larsson2023}. We use the randomized version of the coordinate descent
        updates.

        % \item[PGD] The proximal gradient descent algorithm, which is a standard
        %       algorithm for solving convex optimization problems~\citep{wright2009}. We use a
        %       analytical computation of the Lipschitz constant to pick the step size.
        %
  \item[Anderson PGD] The proximal gradient descent (PGD) algorithm with Anderson acceleration, which is a
        method for accelerating the convergence of fixed-point
        iterations~\citep{anderson1965,zhang2020}.
  \item[BB PGD] The PGD algorithm with Barizilai--Borwein~\citep{barzilai1988} step sizes.

  \item[Safe PGD] A PGD-based algorithm with acceleration using safe screening
        rules~\citep{elvira2023}.

  \item[FISTA] The fast iterative shrinking and thresholding
        algorithm~\citep{beck2009}, which is an accelerated version of iterative
        soft-thresholding algorihthm (ISTA)~\citep{wright2009}.

  \item[ADMM] The alternating direction method of
        multipliers~\citep{glowinski1975,boyd2010}, which is a popular algorithm
        for solving convex optimization problems with constraints. In our experiments,
        we have used \(\rho = 100\) as a step size based on the
        results from \citet{larsson2023}.
        We considered using the heuristic \(\rho\) selection method from
        \citet{boyd2010}, but have avoided to do so since it, as shown by \citet{larsson2023},
        may lead to erratic convergence behavior in practice. We use \fct{lsqr}
        from \pkg{SciPy}~\citep{virtanen2020} to solve the linear system if
        \(\min\{n, p\} > \num{1000}\) and otherwise use solve the linear system
        as suggested by \citet{boyd2010}.

  \item[Newt-ALM] A semi-smooth Newton-based method~\citep{luo2019}. Our
        implementation of this method is based on that from \citet{larsson2023},
        but improved with better heuristics for selecting the inner solver,
        improved conjugate gradient solver, and
        a bug fix for the Woodbury-based solver. For the conjugate gradient solver,
        we use \fct{cg} from \pkg{SciPy}~\citep{virtanen2020}.

  \item[skglm] Another implementation of FISTA from the
        \pkg{skglm} package~\citep{bertrand2022}.

  \item[SolutionPath] An approximate homotopy method by \citet{dupuis2024},
        which is similar to the lars algorithm for the lasso~\citep{efron2004}.
\end{description}

For this paper, we have also created a separate benchmark for fitting the full
regularization path, which is available at
\myurl{github.com/benchopt/benchmark\_slope\_path} and which features a subset
of the solvers from the previous benchmark.

We have run the benchmarks for both simulated~(\Cref{tab:simulated-data}) as
well as real data~(\Cref{tab:real-data}). For all real data, we standardize the
predictors to have mean zero and unit variance. For all data we use the
Benjamini--Hochberg sequence for \(\lambda\) with \(q=0.2\). Since some of the
solvers cannot handle intercepts, we have omitted the intercepts from the
models. Also note that not all solvers support sparse design matrices, which is
why they are not included everywhere.

\begin{table}[tp]
  \centering
  \begin{tabular}{
      l
      S[table-format=5.0]
      S[table-format=7.0]
      S[table-format=1.5,round-mode=figures,round-precision=2]
      p{5cm}
    }
    \toprule
    Dataset                    & {\(n\)} & {\(p\)} & {\(X\) density} & {References}                        \\
    \midrule
    \dataset{BRCA1}            & 536     & 17322   & 1               & \citet{nationalcancerinstitute2022} \\
    \dataset{Koussounadis2014} & 101     & 34694   & 1               & \citet{koussounadis2014}            \\
    \dataset{RCV1}             & 20242   & 44504   & 0.00166         & \citet{lewis2004}                   \\
    \dataset{Real-Sim}         & 72309   & 20958   & 1               & \citet{mccallum2010}                \\
    \dataset{Scheetz2006}      & 842     & 360     & 0.02469         & \citet{scheetz2006}                 \\
    \bottomrule
  \end{tabular}
  \caption{%
    List of real datasets used in our experiments, along with some of
    their properties, including the number of samples \(n\) and predictors \(p\).
    \dataset{BRCA1}, \dataset{Koussounadis2014}, and \dataset{Scheetz2006} were
    obtained from \citet{breheny2022} and the rest from \citet{chang2016}.
  }
  \label{tab:real-data}
\end{table}

\begin{table}[tp]
  \centering
  \begin{tabular}{
      l
      S[table-format=6.0]
      S[table-format=6.0]
      S[table-format=2.0]
      S[table-format=1.3]
      S[table-format=0.1]
    }
    \toprule
    {Scenario}       & {\(n\)} & {\(p\)} & {\(k\)} & {\(X\) density} & {\(\rho\)} \\
    \midrule
    High Dim         & 200     & 20000   & 20      & 1               & 0.6        \\
    High Dim, Sparse & 200     & 200000  & 20      & 0.001           & 0.6        \\
    Low Dim          & 200000  & 200     & 40      & 1               & 0.2        \\
    \bottomrule
  \end{tabular}
  \caption{
    Scenarios for the simulated data in our benchmarks. \(\rho\) is the auto-correlation
    between adjacent predictors, \(k\) is the number of clusters, and
    \(n\) and \(p\) are the number of samples and predictors, respectively.
  }
  \label{tab:simulated-data}
\end{table}

\subsection{Single solution}\label{sec:single-solution-benchmark}

We have parameterized our single-solution benchmarks by \(\alpha\) as a
fraction of \(\alpha_\text{max}\) (the value at which the first cluster enters
the model), and run the benchmarks for \(\alpha = \alpha_\text{max}/2\),
\(\alpha_\text{max}/10\), and \(\alpha_\text{max}/50\). We present convergence using
the duality gap.

The results for the simulated data are presented in \Cref{fig:simulated-data-single}.
We can observe that our algorithm is fastest in every case except
the (\(\alpha_\text{max}/50\), High Dim) combination, where the Newt-ALM
method seems to perform better (although does not quite converge). The difference
is especially pronounced for high levels of regularization, where our method is
often many times faster than the next best method.

\begin{figure}[tp]
  \centering
  \includegraphics[width=\natwidth]{images/benchmark_single_simulated.pdf}
  \caption{%
    Performance of the solvers for the single solution benchmark for three different settings
    of simulated data~(\Cref{tab:simulated-data}).
    Please see the text for information about the data and setup of the experiment.
  }
  \label{fig:simulated-data-single}
\end{figure}

For real data~\Cref{fig:real-data-single}, we see a mostly similar pattern.
Our algorithm (sortedl1) performs best for most combinations---again dominating
in the high-regularization regime, whereas Newt-ALM and occasionally some version of
the accelerated PGD methods or ADMM perform well. Notice, however, that the other algorithms
performance appears to be much more sensitive to the problem, especially the
ADMM method, which sometimes diverges.

\begin{figure}[tp]
  \centering
  \includegraphics[width=\natwidth]{images/benchmark_single_real.pdf}
  \caption{%
    Performance of the solvers for the single solution benchmark for five different real data sets~(\Cref{tab:real-data}).
    Please see the text for information about the data and setup of the experiment.
  }
  \label{fig:real-data-single}
\end{figure}

\subsection{Path}\label{sec:path-benchmark}

Here, we present benchmarks
on a subset of the real data sets from \Cref{tab:real-data}. We parameterize
the benchmark using the lenth of the path, using 50, 100, and 200 steps. We
present the results as the maximum relative duality gap along the path.

The results are presented in \Cref{fig:real-data-path}. Note that the interpretation
of progress towards convergence does not hold quite the same way as for the single
solution benchmarks since we fit a full path. Nevertheless, we note that our
implementation is the fastest by a large margin.

\begin{figure}[tp]
  \centering
  \includegraphics[width=\natwidth]{images/benchmark_path_real.pdf}
  \caption{%
    Benchmark for fitting the full regularization path on real data sets with
    varying grid sizes.
  }
  \label{fig:real-data-path}
\end{figure}

Taken together, our benchmarks show that our method performs better
than all the competing methods.

\section{Discussion}\label{sec:discussion}

SLOPE is an appealing model for high-dimensional regression problems that is
able to provide sparse solutions with a cluster structure, which sets it apart
from similar models such as the lasso and elastic net. Unlike these models,
however, SLOPE represents a more challenging optimization problem since the
penalty term is inseparable. In spite of this, we have shown that it is
possible to solve SLOPE efficiently and have, in this paper, presented a collection
of packages (in \proglang{R}, \proglang{Python}, and \proglang{Julia}) that do
so. We hope that this endeavour will make SLOPE accessible to a wider audience.
Ours are the first packages that implement SLOPE in these languages.
As far as we can tell, the only other packaged implementation of SLOPE
is \pkg{skglm}, which is available in \proglang{Python}. For
\proglang{R} and \proglang{Julia}, ours are the only
available implementations.

We have shown that the performance of our software is unparalleled
compared to other algorithms and implementations, both for for fitting
the full regularization path as well as for single solution, and
have shown these in a series of benchmarks on both real and simulated
data, both for solving for a single solution and for fitting the full path.

Our results mostly echo the results from \citet{larsson2023}, except that
our new implementation performs better. We believe this is likely due to the
addition of screening rules and improvements to the algorithm and implementation.
One difference from \citet{larsson2023} is the performance of the Newt-ALM
method, which in the current benchmarks have performed better. We have
made improvements to the algorithm here that we think help explain this fact.

\citet{dupuis2024} benchmarked the Python implementation of the hybrid
algorithm from \citet{larsson2023} (that our algorithm is based on) against
their approximate homotopy method and showed that their method performed better
in one case and worse in another. In our benchmarks, however, we have
consistently found our algorithm to be superior. One reason for this is that
\citet{dupuis2024} used a very stringent stopping criterion\footnote{A duality
  gap of \(10^{-10}\).} for their benchmarks. Another is that the problem sizes in
our benchmarks are generally larger.

Although our packages are full-fledged implementations of SLOPE, there are
still some features that are missing. For instance, we do not yet support
observation weights, nor some of the more advanced features of similar packages
such as \pkg{glmnet}~\citep{friedman2010}, which allow for a larger variety of
loss functions, including Cox proportional hazards models and multivariate
linear regression. We also do not yet support the group sorted \(\ell_1\) norm,
which would allow an alternative penalization scheme for multivariate response
problems. In addition, several possible improvements to the hybrid method
could be considered, such as accelerated and parallelized coordinate
steps. We leave these possibilities to future work but want to stress that
our packages are modular and have been designed with extensibility in mind,
which we hope will facilitate the addition of new features in the future.
Because all of the packages rely on the same \proglang{C++} library, contributions
will also propagate directly to the higher-level packages in \proglang{R},
\proglang{Julia}, and \proglang{Python}.

% \citet{friedman2010} present an alternative coordinate descent update that is
% based on pre-computing the Gram matrix \(X^\intercal X\) and then use this to
% speed up the updates. As the authors note, this can lead to dramatic speed-ups
% for the ordinary lasso (with least-squares loss), but not for other loss
% functions and not in the high-dimensional setting. Yet, although this type of
% update would be useful for SLOPE as well, it is not implemented in our
% packages. The main reason for this is that the Gram matrix we need is the
% collapsed version \((XP)^\intercal XP\), where \(P\) is the pattern matrix,
% which cannot be derived from \(X^\intercal X\). \(P\) typically changes
% continuously throughout optimization, which means that the precomputed Gram
% matrix must be updated as well, and this would invoke additional cost.

We hope that our packages will be useful for researchers and
practitioners alike and that the design of our software suite
might inspire others to more closely couple the available features
of \proglang{R}, \proglang{Python}, and \proglang{Julia} and avoid
redundant implementations of the same algorithms in each language.

\bibliography{main}

\newpage

\begin{appendix}

  \section{Duality gap and convergence criteria}
  \label{sec:convergence-criteria-details}

  In detail, we transform the primal problem \(P\), defined in \Cref{eq:slope}, into a
  constrained problem, taking \(\alpha = 1\) without loss of generality:
  \begin{equation}
    \label{eq:slope-constrained}
    \begin{aligned}
       & \minimize_{\beta_0 \in \mathbb{R},\beta \in \mathbb{R}^p} &  & \frac{1}{n} \sum_{i=1}^n f(y_i, x_i^\intercal \beta + \beta_0) + J_{\lambda}(\beta) \\
      % & \text{subject to}                                              &  & r_i = \link(\bm{x}_i^\intercal \bm{\beta}) - y_i, \quad i = 1, \ldots, n                                            \\
       & \text{subject to}                                         &  & r_i = \ilink(\beta_0 + x_i^\intercal \beta) - y_i, \quad i = 1, \ldots, n           \\
    \end{aligned}
  \end{equation}

  Since \(\beta_0 + x_i^\intercal \beta = g(r_i + y_i)\), we can write the Lagrangian as
  \[
    L(\beta_0,\beta,r,\delta) = \frac{1}{n} \sum_{i=1}^n f\big(y_i, g(r_i + y_i)\big) + J_{\lambda}(\beta) - \sum_{i=1}^n \delta_i \left(g(r_i + y_i) - x_i^\intercal \beta - \beta_0 \right).
  \]
  This allows us to write the dual problem as
  \[
    D(\delta)  = \inf_r\left( \frac{1}{n} \sum_{i=1}^n f\left(y_i, g(r_i+y_i)\right) - \delta_i g(r_i+ y_i)\right)
    % & \phantom{={}} + \inf_\beta \left(J_\lambda(\beta) - \delta^\intercal X\beta\right)   \\
    % & \phantom{={}} + \inf_{\beta_0} \left( -\delta^\intercal \bm{1} \beta_0\right)        \\
    - \sup_\beta \big((-X^\intercal \delta)^\intercal \beta -  J_\lambda(\beta) \big)
    - \sup_{\beta_0} \left( \delta^\intercal \bm{1} \beta_0\right).
  \]
  Here, we begin by noting that the infimum is attained at the point where
  \(r = \delta\)~\citep{fercoq2015}, which means that the value is
  \[
    \frac{1}{n} \sum_{i=1}^n f\left(y_i, g(\delta_i+y_i)\right) - \delta_i g(\delta_i + y_i)
  \]
  in general, although loss-specific simplifications can be made. For instance, in the case of
  quadratic loss the expression evaluates to \(\frac{1}{2} \lVert y \rVert_2^2 - \frac{1}{2} \lVert \delta + y \lVert^2_2 \).

  Next, we observe that \(\sup_\beta \big((-X^\intercal
  \delta)^\intercal \beta -  J_\lambda(\beta) \big)\) is the Fenchel conjugate of
  the sorted \(\ell_1\) norm, which is the indicator function of the sorted
  \(\ell_1\) dual norm unit ball. Its value is
  \[
    \sup_\beta \big(z^\intercal \beta -  J_\lambda(\beta) \big) =
    \begin{cases}
      0      & \text{if } J^*_\lambda(z) \leq 1, \\
      \infty & \text{otherwise},
    \end{cases}
  \]
  where \(J^*_\lambda(z)\) is the sorted \(\ell_1\) dual norm, defined as~\citep{negrinho2014}
  \begin{equation}
    J^*_\lambda(z) = \max_{j=1,2,\dots,p}\left\{ \frac{\sum_{k=1}^j|z_{(k)}|}{\sum_{k=1}^j\lambda_k}\right\}
  \end{equation}

  Next, observe that \(\sup_{\beta_0} (\delta^\intercal \bm{1} \beta_0) = \infty\) unless
  \(\delta^\intercal \bm{1} = 0\).

  Taken together, this means that we have the following dual function:
  \begin{equation}
    D(\delta) = \begin{cases}
      \frac{1}{n} \sum_{i=1}^n f\left(y_i, g(\delta_i+y_i)\right) - \delta_i g(\delta_i+ y_i) & \text{if } J^*_\lambda(-X^\intercal \delta) \leq 1 \text{ and } \delta^\intercal \bm{1} = 0 \\
      -\infty,                                                                                & \text{otherwise}.
    \end{cases}
  \end{equation}

  A natural dual point candidate for this problem is to pick
  \(\delta = r\), since
  at the optimum we have
  \[
    \bm{0} \in X^\intercal r + \partial J_\lambda(X^\intercal r)
  \]
  and, in addition require that the signs between agree.
  % TODO: Hand-wavy, clean up later.

  % To obtain a feasible dual point for this problem, we can use the
  % following fact about the stationarity condition of the primal problem,
  % namely that
  % \[
  %   \sum_{j=1}^k | g_{(j)} | \leq \sum_{j=1}^k \lambda_j |\beta_{(j)}| \quad \forall\; k = 1,2,\dots,p.
  % \]
  % where  \(g_j = x_j^\intercal r\) is the \(j\)th component of the gradient of loss function
  % with respect to \(\beta_j\)
  % and \(r\) the generalized residual, for which \(r_i = \ilink(x_i^\intercal \beta + \beta_0) - y_i\).

  To be a feasible point, however, we first center the point by its mean and
  scale it:
  \[
    \delta_j = \frac{r_i - \bar{r}}{\max\left\{1, J_\lambda^*\left(X^\intercal(r - \bar{r})\right) \right\}}
  \]
  which guarantees feasibility. We then obtain the following duality gap:
  \[
    P(\beta_0, \beta) - D(\delta).
  \]
  As a stopping criterion for the algorithm, we use the relative duality gap
  \[
    P(\beta_0, \beta) - D(\delta) \leq \varepsilon P(\beta_0),
  \]
  where \(\varepsilon >0\) is the user-defined tolerance level.
  The duality gap provides an upper bound on suboptimality for the problem, independent
  of solver and conditioning of the problem, which is not the case of
  convergence criteria based on changes in objective, gradients, or coefficients.

  The availability of the duality gap would also allow us to employ
  duality-gap based safe screening rules~\citep{fercoq2015} and
  working set strategies derived from these~\citep{massias2018}, which
  could furthermore be used to enhance our strategy with look-ahead
  screening rules~\citep{larsson2021a}. However,
  as noted in \citet{larsson2022d}, the marginal improvement
  of using duality-based screening strategies is minor, so we have
  opted not to implement these in our packages.
  % TODO: Maybe reconsider this!

\end{appendix}

\end{document}
