\documentclass[article]{jss}

\usepackage{orcidlink,thumbpdf,lmodern}
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}

\usepackage{amssymb,amsmath,amsthm,mathtools,bm}
\usepackage{upquote}

\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts

\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{siunitx}

\usepackage{enumitem}

\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{crossreftools}
\pdfstringdefDisableCommands{%
  \let\Cref\crtCref
  \let\cref\crtcref
}

\usepackage{todonotes}

\input{tex/macros}

% setup url command for hyperref
\newcommand{\myurl}[1]{\href{https://#1}{\nolinkurl{#1}}}

\author{Johan Larsson~\orcidlink{0000-0002-4029-5945}\\University of Copenhagen
   \And Second Author\\Plus Affiliation}
\Plainauthor{}

\title{Efficient Solvers for SLOPE in \proglang{R}, \proglang{Python}, \proglang{Julia}, and \proglang{C++}}
\Plaintitle{Efficient Solvers for SLOPE in R, Python, Julia, and C++}
\Shorttitle{Efficient Solvers for SLOPE}

\Abstract{
  We present a collection of packages in \proglang{R}, \proglang{Python},
  \proglang{Julia}, and \proglang{C++} to efficiently solve the full
  regularization path for Sorted L-One Penalized Estimation (SLOPE) in
  \proglang{R}, \proglang{Python}, \proglang{Julia}, and \proglang{C++}.
  The packages feature a new and improved implementation of the 
  hybrid coordinate descent algorithm for solving SLOPE, which
  features improved and robust convergence properties.
}

\Keywords{SLOPE, OWL, regularization, generalized linear models, \proglang{R}, \proglang{Python}, \proglang{Julia}, \proglang{C++}}
\Plainkeywords{SLOPE, OWL, regularization, generalized linear models, R, Python, C++}

\Address{
  Johan Larsson\\
  Department of Mathematical Sciences\\
  Faculty of Science\\
  University of Copenhagen\\
  Universitetsparken 5\\
  2100 København Ø, Denmark\\
  E-mail: \email{jolars@posteo.com}\\
  URL: \url{https://jolars.co/}
}

\begin{document}

\section{Introduction}

Sorted L-One Penalized Estimation
(SLOPE)~\citep{bogdan2013,zeng2014,bogdan2015} is a type of
regularized regression that consists of following convex optimization problem:
\begin{equation}
  \label{eq:slope}
  \minimize_{\beta_0,\bm{\beta}} \left( \frac{1}{n} \sum_{i=1}^n f(\bm{y}_i, \beta_0 + \bm{\beta}^\intercal \bm{x}_i) + \alpha J_{\bm{\lambda}}(\bm{\beta})\right)
\end{equation}
where \((\bm{y}_i, \bm{x}_i)\) is the \(i\)th observation, \(\alpha\) a parameter
that controls the strength of regularization, and \(\bm{\lambda}\) a non-increasing sequence of penalty weights. \(J\) is the
\emph{sorted $\ell_1$ norm}, defined as
\begin{equation}
  \label{eq:sl1}
  J_{\bm{\lambda}}(\bm{\beta}) = \sum_{j=1}^p \lambda_j |\beta_{(j)}|, \quad
  \text{where}\quad |\beta_{(1)}| \geq |\beta_{(2)}| \geq \ldots \geq
  |\beta_{(p)}|.
\end{equation}
We let \((\hat{\beta}_0, \hat{\bm{\beta}})\) denote a solution to the problem in \Cref{eq:slope}.

We take \(\bm{X}\) to be the \(n \times p\) design matrix and \(\bm{Y}\) the
\(n \times m\) response matrix.\footnote{For our case, \(m = 1\) unless
  the model is multinomial logistic regression.}

SLOPE is a generalization of OSCAR (octagonal shrinkage and clustering
algorithm for regression)~\citep{bondell2008} and serves as an alternative to the
lasso~\citep{santosa1986,donoho1994,donoho1995,tibshirani1996}, elastic
net~\citep{zou2005}, the SCAD (smoothly clipped absolute deviation)
penalty~\citep{fan2001}, and the MCP~(minimax concave
penalty)~\citep{zhang2010} for sparse regression.

One of the main advantages of SLOPE is that it deals naturally with
correlated predictors by clustering them together. This is a natural
consequence of the sorted \(\ell_1\) norm.

\section{Coordinate Descent for SLOPE}

\section{Mathematical Details}

\subsection{Solvers}

The packages feature multiple solvers, currently proximal gradient descent,
FISTA (fast iterative thresholding algorithm), and the hybrid
coordinate descent method. The codebase is modular by design, so
adding new solvers is straightforward.

\subsection{Convergence Criteria}

Our packages use a duality-based stopping criterion, providing an upper
bound on suboptimality at convergence. To achieve this, we

\section{Technical Details}

\subsection{Sparsity}

Our package interfaces directly with the Eigen library and handles
sparse design matrices in a natural fashion. In \proglang{R}, these
can be created directly through the \pkg{Matrix} package, and in
\proglang{Python} through the \pkg{scipy.sparse} package. In
\proglang{Julia}, we use the \pkg{SparseArrays} package, which is
part of the standard library.

The returned coefficients are also stored in a sparse format, which
allows for efficient storage and retrieval of the coefficients. This

\subsection{Parallelization}

The software is parallelized using OpenMP, which is supported
on all major platforms\footnote{Although overhead for creating
  multiple threads is considerably more demanding on Windows}.
Functions make use of heuristics to determine whether to
spawn multiple threads depending on problem size, except for
the embarassingly parallel case of cross-validation, which is always
parallelized.

\subsection{Out-of-Memory Support}

% TODO: Should we implement this? would be nice.

\subsection{Implementation}

In this paper we present a collection of packages for solving SLOPE, currently
with support for fitting SLOPE in \proglang{R}, \proglang{Python}, and
\proglang{Julia}. The backbone of all of these packages is based on a
\proglang{C++} library that implements all of the numerical algorithms for
SLOPE, including preprocessing, cross-validation, and path fitting. The
packages for the high-level languages all serve as thin wrappers to the
\proglang{C++} library, with some additional functionality for handling data
and plotting the results. This means that new features and bug fixes propagate
quickly and easily to all these wrapppers and enable users to promptly take
advantage of the latest developments.

The entire suite of packages is open source and licensed under the GPL-3.0 license,
and is available on GitHub~(\Cref{tab:slope-packages}).

\begin{table}[htpb]
  \centering
  \caption{SLOPE packages}
  \label{tab:slope-packages}
  \begin{tabular}{llll}
    \toprule
    Language          & Package        & Repository                         & Documentation                     \\
    \midrule
    \proglang{R}      & \pkg{SLOPE}    & \myurl{github.com/jolars/SLOPE}    & \myurl{jolars.github.io/libslope} \\
    \proglang{Python} & \pkg{sortedl1} & \myurl{github.com/jolars/sortedl1} & \myurl{jolars.github.io/sortedl1} \\
    \proglang{Julia}  & \pkg{SLOPE.jl} & \myurl{github.com/jolars/SLOPE.jl} & \myurl{jolars.github.io/SLOPE.jl} \\
    \proglang{C++}    & \pkg{slope}    & \myurl{github.com/jolars/libslope} & \myurl{jolars.github.io/libslope} \\
    \bottomrule
  \end{tabular}
\end{table}

This is made possible via several pieces of software that enable us to link the
API from our \proglang{C++} library to the high-level languages. This includes
\pkg{Rcpp}~\citep{eddelbuettel2011} and \pkg{RcppEigen}~\citep{bates2013} for
\proglang{R}, \pkg{pybind11}~\citep{jakob2025}, and \pkg{CxxWrap}~\citep{janssens2020} for
\proglang{Julia}.

\section{Examples}

In this section we will show how to use the packages to fit SLOPE models in
the different languages.

The packages are
available through the respective package managers for each language, and can be
be installed using the following commands:

\begin{description}[labelwidth=8ex]
  \item[\proglang{R}] \code{install.packages("SLOPE")}
  \item[\proglang{Python}] \code{pip install sortedl1}
  \item[\proglang{Julia}] \code{using Pkg; Pkg.add("SLOPE")}
\end{description}

\section{Benchmarks}

\bibliography{main}

\newpage

\begin{appendix}

\end{appendix}

\end{document}
